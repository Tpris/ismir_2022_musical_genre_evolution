{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3407384c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import pyreadr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dbe6e1",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d32e43e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "data = pyreadr.read_r('song_data.rds') \n",
    "data = data[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21bd1c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1994\n",
      "1        2017\n",
      "2        2015\n",
      "3        2016\n",
      "4        2015\n",
      "         ... \n",
      "94811    2012\n",
      "94812    2015\n",
      "94813    2015\n",
      "94814    2016\n",
      "94815    2015\n",
      "Name: release_year, Length: 94816, dtype: int64\n",
      "            song_id   tag release_date  release_month  release_year  \\\n",
      "1       xNgVaKafcd0   pop   2017-09-08    2017.666667        2017.0   \n",
      "2       mSOdaq656ff  rock   2015-11-11    2015.833333        2015.0   \n",
      "3      bqv5oMs3aac9   pop   2016-05-24    2016.333333        2016.0   \n",
      "4       xLBr1fbf8ac   pop   2015-06-27    2015.416667        2015.0   \n",
      "5      bqwPhDt3af1d   pop   2016-04-14    2016.250000        2016.0   \n",
      "...             ...   ...          ...            ...           ...   \n",
      "94811   mSFWvm87f0a   pop   2012-07-12    2012.500000        2012.0   \n",
      "94812   xNPVxjbf14e   pop   2015-04-08    2015.250000        2015.0   \n",
      "94813   8IAUlNe26fb   pop   2015-04-08    2015.250000        2015.0   \n",
      "94814  bCniNa4469b4   pop   2016-04-08    2016.250000        2016.0   \n",
      "94815   xNPVxla3162   pop   2015-04-08    2015.250000        2015.0   \n",
      "\n",
      "       listen_times  chroma_stft_norm  rmse_norm  spectral_centroid_norm  \\\n",
      "1             952.0          0.313235   0.226911                0.325286   \n",
      "2             601.0          0.553648   0.305978                0.255246   \n",
      "3             425.0          0.317953   0.153784                0.248175   \n",
      "4           42450.0          0.295309   0.174921                0.247695   \n",
      "5             352.0          0.359844   0.161044                0.276050   \n",
      "...             ...               ...        ...                     ...   \n",
      "94811          24.0          0.420810   0.162462                0.345590   \n",
      "94812         172.0          0.302126   0.199702                0.278044   \n",
      "94813          84.0          0.584518   0.210099                0.487939   \n",
      "94814         222.0          0.367468   0.317775                0.482698   \n",
      "94815         252.0          0.536630   0.488423                0.367835   \n",
      "\n",
      "       spectral_bandwidth_norm  ...  mfcc11_norm  mfcc12_norm  mfcc13_norm  \\\n",
      "1                     0.570343  ...     0.411552     0.365625     0.359362   \n",
      "2                     0.479821  ...     0.717449     0.484404     0.558664   \n",
      "3                     0.558457  ...     0.569084     0.339578     0.534756   \n",
      "4                     0.550785  ...     0.567201     0.407748     0.466743   \n",
      "5                     0.628411  ...     0.639329     0.453601     0.532991   \n",
      "...                        ...  ...          ...          ...          ...   \n",
      "94811                 0.702055  ...     0.620151     0.396508     0.535819   \n",
      "94812                 0.568268  ...     0.655453     0.445301     0.584849   \n",
      "94813                 0.758034  ...     0.668336     0.479782     0.570788   \n",
      "94814                 0.781361  ...     0.613877     0.455672     0.503346   \n",
      "94815                 0.685609  ...     0.668894     0.543448     0.535637   \n",
      "\n",
      "       mfcc14_norm  mfcc15_norm  mfcc16_norm  mfcc17_norm  mfcc18_norm  \\\n",
      "1         0.429784     0.461608     0.443594     0.433783     0.280255   \n",
      "2         0.522273     0.536892     0.555597     0.530681     0.281744   \n",
      "3         0.402370     0.505196     0.531985     0.452319     0.275470   \n",
      "4         0.482210     0.478182     0.539164     0.399455     0.224764   \n",
      "5         0.493482     0.473726     0.570167     0.437348     0.286538   \n",
      "...            ...          ...          ...          ...          ...   \n",
      "94811     0.517048     0.471246     0.574771     0.495532     0.282261   \n",
      "94812     0.597828     0.564444     0.650760     0.502584     0.267097   \n",
      "94813     0.578115     0.513767     0.634211     0.576412     0.329460   \n",
      "94814     0.528070     0.467975     0.578993     0.504241     0.297636   \n",
      "94815     0.654647     0.519921     0.638721     0.538924     0.293353   \n",
      "\n",
      "       mfcc19_norm  mfcc20_norm  \n",
      "1         0.320974     0.607268  \n",
      "2         0.344796     0.510593  \n",
      "3         0.249064     0.486048  \n",
      "4         0.347304     0.591887  \n",
      "5         0.284802     0.470208  \n",
      "...            ...          ...  \n",
      "94811     0.318730     0.520840  \n",
      "94812     0.306384     0.557927  \n",
      "94813     0.324301     0.581597  \n",
      "94814     0.283562     0.570311  \n",
      "94815     0.305440     0.540737  \n",
      "\n",
      "[69427 rows x 32 columns]\n",
      "tag  release_year  folk  hiphop   pop  rock\n",
      "0          2009.0   177      54   963   204\n",
      "1          2010.0   140     137  1079   227\n",
      "2          2011.0   279     113  1023   415\n",
      "3          2012.0   289     271  1251   473\n",
      "4          2013.0   438     314  1660   564\n",
      "5          2014.0   802     804  2432  1211\n",
      "6          2015.0  1297     918  2882  1687\n",
      "7          2016.0  1072     849  3908  1447\n",
      "8          2017.0  1775    2365  6497  2203\n",
      "9          2018.0  1902    3636  9687  1940\n",
      "10         2019.0   900    2359  5486  1297\n",
      "tag  release_year  folk  hiphop   pop  rock    sum  folk_prop  hiphop_prop  \\\n",
      "0          2009.0   177      54   963   204   1398   0.126609     0.038627   \n",
      "1          2010.0   140     137  1079   227   1583   0.088440     0.086545   \n",
      "2          2011.0   279     113  1023   415   1830   0.152459     0.061749   \n",
      "3          2012.0   289     271  1251   473   2284   0.126532     0.118651   \n",
      "4          2013.0   438     314  1660   564   2976   0.147177     0.105511   \n",
      "5          2014.0   802     804  2432  1211   5249   0.152791     0.153172   \n",
      "6          2015.0  1297     918  2882  1687   6784   0.191185     0.135318   \n",
      "7          2016.0  1072     849  3908  1447   7276   0.147334     0.116685   \n",
      "8          2017.0  1775    2365  6497  2203  12840   0.138240     0.184190   \n",
      "9          2018.0  1902    3636  9687  1940  17165   0.110807     0.211826   \n",
      "10         2019.0   900    2359  5486  1297  10042   0.089624     0.234913   \n",
      "\n",
      "tag  pop_prop  rock_prop  \n",
      "0    0.688841   0.145923  \n",
      "1    0.681617   0.143399  \n",
      "2    0.559016   0.226776  \n",
      "3    0.547723   0.207093  \n",
      "4    0.557796   0.189516  \n",
      "5    0.463326   0.230711  \n",
      "6    0.424823   0.248673  \n",
      "7    0.537108   0.198873  \n",
      "8    0.505997   0.171573  \n",
      "9    0.564346   0.113021  \n",
      "10   0.546306   0.129158  \n"
     ]
    }
   ],
   "source": [
    "data['release_year'] = pd.to_datetime(data['release_date']).dt.year\n",
    "print(data['release_year'])\n",
    "data_genres_composition = data.where(data['release_year'].isin([2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019]))\n",
    "data_genres_composition = data_genres_composition.dropna(how='all')\n",
    "print(data_genres_composition)\n",
    "data_genres_composition = data_genres_composition.groupby(['release_year', 'tag']).size().unstack().reset_index()\n",
    "print(data_genres_composition)\n",
    "visu_data = data_genres_composition.copy()\n",
    "data_genres_composition['sum'] = data_genres_composition['folk'] + data_genres_composition['hiphop'] + data_genres_composition['pop'] + data_genres_composition['rock']\n",
    "data_genres_composition['folk_prop'] = data_genres_composition['folk'] / data_genres_composition['sum']\n",
    "data_genres_composition['hiphop_prop'] = data_genres_composition['hiphop'] / data_genres_composition['sum']\n",
    "data_genres_composition['pop_prop'] = data_genres_composition['pop'] / data_genres_composition['sum']\n",
    "data_genres_composition['rock_prop'] = data_genres_composition['rock'] / data_genres_composition['sum']\n",
    "print(data_genres_composition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95c2777",
   "metadata": {},
   "source": [
    "## Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "052e88ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = visu_data.plot.bar(x='release_year',stacked=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5be6340",
   "metadata": {},
   "source": [
    "# Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abf26d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml_data = data[data['release_year'] == 2009].nlargest(50, 'listen_times')\n",
    "ml_data = data[data['release_year'] == 2009]\n",
    "\n",
    "# Split data into train and test sets\n",
    "ml_train, ml_test = train_test_split(ml_data, test_size=0.2, random_state=210016, shuffle=True)\n",
    "\n",
    "# Select features for training and testing\n",
    "ml_train = ml_train.iloc[:, [1] + list(range(6, 17))]\n",
    "ml_test = ml_test.iloc[:, [1] + list(range(6, 17))]\n",
    "\n",
    "y_true = ml_test['tag'].to_numpy()\n",
    "y_true = np.unique(y_true, return_inverse=True)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8b546e",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5702c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6082289803220036\n",
      "0.6285714285714286\n",
      "0.7539339972071808\n"
     ]
    }
   ],
   "source": [
    "nb_model = GaussianNB()\n",
    "nb_model.fit(ml_train.iloc[:, 1:], ml_train.iloc[:, 0])\n",
    "p_train = nb_model.predict(ml_train.iloc[:, 1:])\n",
    "p_train_prob = nb_model.predict_proba(ml_train.iloc[:, 1:])\n",
    "print(np.mean(p_train == ml_train.iloc[:, 0]))\n",
    "p_test = nb_model.predict(ml_test.iloc[:, 1:])\n",
    "p_test_prob = nb_model.predict_proba(ml_test.iloc[:, 1:])\n",
    "print(np.mean(p_test == ml_test.iloc[:, 0]))\n",
    "print(roc_auc_score(y_true, p_test_prob, multi_class='ovr'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94aeaa95",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b7ee0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "    k       acc       auc\n",
      "0   9  0.760714  0.812217\n",
      "0   8  0.757143  0.806108\n",
      "0  11  0.757143  0.805675\n",
      "0  17  0.753571  0.798068\n",
      "0  16  0.753571  0.800327\n",
      "0   6  0.753571  0.783771\n",
      "0  18  0.750000  0.796110\n",
      "0  12  0.750000  0.810317\n",
      "0  30  0.746429  0.797897\n",
      "0  14  0.746429  0.801806\n",
      "0  15  0.742857  0.806074\n",
      "0  26  0.739286  0.802067\n",
      "0  10  0.739286  0.812230\n",
      "0  19  0.739286  0.800169\n",
      "0  20  0.735714  0.797545\n",
      "0  27  0.735714  0.800991\n",
      "0  28  0.735714  0.800089\n",
      "0  31  0.735714  0.799203\n",
      "0  25  0.735714  0.791698\n",
      "0  40  0.735714  0.794580\n",
      "0  39  0.735714  0.794185\n",
      "0   7  0.732143  0.802957\n",
      "0  29  0.732143  0.798829\n",
      "0   3  0.732143  0.770056\n",
      "0  32  0.732143  0.798421\n",
      "0  37  0.728571  0.794015\n",
      "0  36  0.728571  0.796204\n",
      "0  23  0.728571  0.796533\n",
      "0  24  0.728571  0.794037\n",
      "0  35  0.728571  0.793135\n",
      "0  13  0.728571  0.804100\n",
      "0  38  0.728571  0.795052\n",
      "0  33  0.728571  0.797327\n",
      "0  34  0.728571  0.795454\n",
      "0  21  0.725000  0.797981\n",
      "0  22  0.721429  0.797542\n",
      "0   5  0.717857  0.770282\n",
      "0   4  0.714286  0.757121\n",
      "0   1  0.710714  0.704658\n",
      "0   2  0.685714  0.754639\n"
     ]
    }
   ],
   "source": [
    "df_knn_auc = pd.DataFrame(columns=['k', 'acc', 'auc'])\n",
    "for k in range(1, 41):\n",
    "    print(k)\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn_model.fit(ml_train.iloc[:, 1:], ml_train.iloc[:, 0])\n",
    "    knn_model_prob = knn_model.predict_proba(ml_test.iloc[:, 1:])\n",
    "    y_pred_lab = knn_model.predict(ml_test.iloc[:, 1:])\n",
    "    acc = np.mean(y_pred_lab == ml_test.iloc[:, 0])\n",
    "    auc = roc_auc_score(y_true, knn_model_prob, multi_class='ovr')\n",
    "    # df_knn_auc = df_knn_auc.append({'k': k, 'acc': acc, 'auc': auc}, ignore_index=True)\n",
    "    df_knn_auc = pd.concat([df_knn_auc, pd.DataFrame.from_records([{'k': k, 'acc': acc, 'auc': auc}])])\n",
    "df_knn_auc = df_knn_auc.sort_values(by='acc', ascending=False)\n",
    "print(df_knn_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b106fd3",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd50dd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth : 20\n",
      "depth : 21\n",
      "depth : 22\n",
      "depth : 23\n",
      "depth : 24\n",
      "depth : 25\n",
      "depth : 26\n",
      "depth : 27\n",
      "depth : 28\n",
      "depth : 29\n",
      "depth : 30\n",
      "depth : 31\n",
      "depth : 32\n",
      "depth : 33\n",
      "depth : 34\n",
      "depth : 35\n",
      "depth : 36\n",
      "depth : 37\n",
      "depth : 38\n",
      "depth : 39\n",
      "depth : 40\n",
      "n : 20\n",
      "depth : 20\n",
      "depth : 21\n",
      "depth : 22\n",
      "depth : 23\n",
      "depth : 24\n",
      "depth : 25\n",
      "depth : 26\n",
      "depth : 27\n",
      "depth : 28\n",
      "depth : 29\n",
      "depth : 30\n",
      "depth : 31\n",
      "depth : 32\n",
      "depth : 33\n",
      "depth : 34\n",
      "depth : 35\n",
      "depth : 36\n",
      "depth : 37\n",
      "depth : 38\n",
      "depth : 39\n",
      "depth : 40\n",
      "n : 21\n",
      "depth : 20\n",
      "depth : 21\n",
      "depth : 22\n",
      "depth : 23\n",
      "depth : 24\n",
      "depth : 25\n",
      "depth : 26\n",
      "depth : 27\n",
      "depth : 28\n",
      "depth : 29\n",
      "depth : 30\n",
      "depth : 31\n",
      "depth : 32\n",
      "depth : 33\n",
      "depth : 34\n",
      "depth : 35\n",
      "depth : 36\n",
      "depth : 37\n",
      "depth : 38\n",
      "depth : 39\n",
      "depth : 40\n",
      "n : 22\n",
      "depth : 20\n",
      "depth : 21\n",
      "depth : 22\n",
      "depth : 23\n",
      "depth : 24\n",
      "depth : 25\n",
      "depth : 26\n",
      "depth : 27\n",
      "depth : 28\n",
      "depth : 29\n",
      "depth : 30\n",
      "depth : 31\n",
      "depth : 32\n",
      "depth : 33\n",
      "depth : 34\n",
      "depth : 35\n",
      "depth : 36\n",
      "depth : 37\n",
      "depth : 38\n",
      "depth : 39\n",
      "depth : 40\n",
      "n : 23\n",
      "depth : 20\n",
      "depth : 21\n",
      "depth : 22\n",
      "depth : 23\n",
      "depth : 24\n",
      "depth : 25\n",
      "depth : 26\n",
      "depth : 27\n",
      "depth : 28\n",
      "depth : 29\n",
      "depth : 30\n",
      "depth : 31\n",
      "depth : 32\n",
      "depth : 33\n",
      "depth : 34\n",
      "depth : 35\n",
      "depth : 36\n",
      "depth : 37\n",
      "depth : 38\n",
      "depth : 39\n",
      "depth : 40\n",
      "n : 24\n",
      "depth : 20\n",
      "depth : 21\n",
      "depth : 22\n",
      "depth : 23\n",
      "depth : 24\n",
      "depth : 25\n",
      "depth : 26\n",
      "depth : 27\n",
      "depth : 28\n",
      "depth : 29\n",
      "depth : 30\n",
      "depth : 31\n",
      "depth : 32\n",
      "depth : 33\n",
      "depth : 34\n",
      "depth : 35\n",
      "depth : 36\n",
      "depth : 37\n",
      "depth : 38\n",
      "depth : 39\n",
      "depth : 40\n",
      "n : 25\n",
      "depth : 20\n",
      "depth : 21\n",
      "depth : 22\n",
      "depth : 23\n",
      "depth : 24\n",
      "depth : 25\n",
      "depth : 26\n",
      "depth : 27\n",
      "depth : 28\n",
      "depth : 29\n",
      "depth : 30\n",
      "depth : 31\n",
      "depth : 32\n",
      "depth : 33\n",
      "depth : 34\n",
      "depth : 35\n",
      "depth : 36\n",
      "depth : 37\n",
      "depth : 38\n",
      "depth : 39\n",
      "depth : 40\n",
      "n : 26\n",
      "depth : 20\n",
      "depth : 21\n",
      "depth : 22\n",
      "depth : 23\n",
      "depth : 24\n",
      "depth : 25\n",
      "depth : 26\n",
      "depth : 27\n",
      "depth : 28\n",
      "depth : 29\n",
      "depth : 30\n",
      "depth : 31\n",
      "depth : 32\n",
      "depth : 33\n",
      "depth : 34\n",
      "depth : 35\n",
      "depth : 36\n",
      "depth : 37\n",
      "depth : 38\n",
      "depth : 39\n",
      "depth : 40\n",
      "n : 27\n",
      "depth : 20\n",
      "depth : 21\n",
      "depth : 22\n",
      "depth : 23\n",
      "depth : 24\n",
      "depth : 25\n",
      "depth : 26\n",
      "depth : 27\n",
      "depth : 28\n",
      "depth : 29\n",
      "depth : 30\n",
      "depth : 31\n",
      "depth : 32\n",
      "depth : 33\n",
      "depth : 34\n",
      "depth : 35\n",
      "depth : 36\n",
      "depth : 37\n",
      "depth : 38\n",
      "depth : 39\n",
      "depth : 40\n",
      "n : 28\n",
      "depth : 20\n",
      "depth : 21\n",
      "depth : 22\n",
      "depth : 23\n",
      "depth : 24\n",
      "depth : 25\n",
      "depth : 26\n",
      "depth : 27\n",
      "depth : 28\n",
      "depth : 29\n",
      "depth : 30\n",
      "depth : 31\n",
      "depth : 32\n",
      "depth : 33\n",
      "depth : 34\n",
      "depth : 35\n",
      "depth : 36\n",
      "depth : 37\n",
      "depth : 38\n",
      "depth : 39\n",
      "depth : 40\n",
      "n : 29\n",
      "depth : 20\n",
      "depth : 21\n",
      "depth : 22\n",
      "depth : 23\n",
      "depth : 24\n",
      "depth : 25\n",
      "depth : 26\n",
      "depth : 27\n",
      "depth : 28\n",
      "depth : 29\n",
      "depth : 30\n",
      "depth : 31\n",
      "depth : 32\n",
      "depth : 33\n",
      "depth : 34\n",
      "depth : 35\n",
      "depth : 36\n",
      "depth : 37\n",
      "depth : 38\n",
      "depth : 39\n",
      "depth : 40\n",
      "n : 30\n",
      "depth : 20\n",
      "depth : 21\n",
      "depth : 22\n",
      "depth : 23\n",
      "depth : 24\n",
      "depth : 25\n",
      "depth : 26\n",
      "depth : 27\n",
      "depth : 28\n",
      "depth : 29\n",
      "depth : 30\n",
      "depth : 31\n",
      "depth : 32\n",
      "depth : 33\n",
      "depth : 34\n",
      "depth : 35\n",
      "depth : 36\n",
      "depth : 37\n",
      "depth : 38\n",
      "depth : 39\n",
      "depth : 40\n",
      "n : 31\n",
      "depth : 20\n",
      "depth : 21\n",
      "depth : 22\n",
      "depth : 23\n",
      "depth : 24\n",
      "depth : 25\n",
      "depth : 26\n",
      "depth : 27\n",
      "depth : 28\n",
      "depth : 29\n",
      "depth : 30\n",
      "depth : 31\n",
      "depth : 32\n",
      "depth : 33\n",
      "depth : 34\n",
      "depth : 35\n",
      "depth : 36\n",
      "depth : 37\n",
      "depth : 38\n",
      "depth : 39\n",
      "depth : 40\n",
      "n : 32\n",
      "depth : 20\n",
      "depth : 21\n",
      "depth : 22\n",
      "depth : 23\n",
      "depth : 24\n",
      "depth : 25\n",
      "depth : 26\n",
      "depth : 27\n",
      "depth : 28\n",
      "depth : 29\n",
      "depth : 30\n",
      "depth : 31\n",
      "depth : 32\n",
      "depth : 33\n",
      "depth : 34\n",
      "depth : 35\n",
      "depth : 36\n",
      "depth : 37\n",
      "depth : 38\n",
      "depth : 39\n",
      "depth : 40\n",
      "n : 33\n",
      "depth : 20\n",
      "depth : 21\n",
      "depth : 22\n",
      "depth : 23\n",
      "depth : 24\n",
      "depth : 25\n",
      "depth : 26\n",
      "depth : 27\n",
      "depth : 28\n",
      "depth : 29\n",
      "depth : 30\n",
      "depth : 31\n",
      "depth : 32\n",
      "depth : 33\n",
      "depth : 34\n",
      "depth : 35\n",
      "depth : 36\n",
      "depth : 37\n",
      "depth : 38\n",
      "depth : 39\n",
      "depth : 40\n",
      "n : 34\n",
      "depth : 20\n",
      "depth : 21\n",
      "depth : 22\n",
      "depth : 23\n",
      "depth : 24\n",
      "depth : 25\n",
      "depth : 26\n",
      "depth : 27\n",
      "depth : 28\n",
      "depth : 29\n",
      "depth : 30\n",
      "depth : 31\n",
      "depth : 32\n",
      "depth : 33\n",
      "depth : 34\n",
      "depth : 35\n",
      "depth : 36\n",
      "depth : 37\n",
      "depth : 38\n",
      "depth : 39\n",
      "depth : 40\n",
      "n : 35\n",
      "depth : 20\n",
      "depth : 21\n",
      "depth : 22\n",
      "depth : 23\n",
      "depth : 24\n",
      "depth : 25\n",
      "depth : 26\n",
      "depth : 27\n",
      "depth : 28\n",
      "depth : 29\n",
      "depth : 30\n",
      "depth : 31\n",
      "depth : 32\n",
      "depth : 33\n",
      "depth : 34\n",
      "depth : 35\n",
      "depth : 36\n",
      "depth : 37\n",
      "depth : 38\n",
      "depth : 39\n",
      "depth : 40\n",
      "n : 36\n",
      "depth : 20\n",
      "depth : 21\n",
      "depth : 22\n",
      "depth : 23\n",
      "depth : 24\n",
      "depth : 25\n",
      "depth : 26\n",
      "depth : 27\n",
      "depth : 28\n",
      "depth : 29\n",
      "depth : 30\n",
      "depth : 31\n",
      "depth : 32\n",
      "depth : 33\n",
      "depth : 34\n",
      "depth : 35\n",
      "depth : 36\n",
      "depth : 37\n",
      "depth : 38\n",
      "depth : 39\n",
      "depth : 40\n",
      "n : 37\n",
      "depth : 20\n",
      "depth : 21\n",
      "depth : 22\n",
      "depth : 23\n",
      "depth : 24\n",
      "depth : 25\n",
      "depth : 26\n",
      "depth : 27\n",
      "depth : 28\n",
      "depth : 29\n",
      "depth : 30\n",
      "depth : 31\n",
      "depth : 32\n",
      "depth : 33\n",
      "depth : 34\n",
      "depth : 35\n",
      "depth : 36\n",
      "depth : 37\n",
      "depth : 38\n",
      "depth : 39\n",
      "depth : 40\n",
      "n : 38\n",
      "depth : 20\n",
      "depth : 21\n",
      "depth : 22\n",
      "depth : 23\n",
      "depth : 24\n",
      "depth : 25\n",
      "depth : 26\n",
      "depth : 27\n",
      "depth : 28\n",
      "depth : 29\n",
      "depth : 30\n",
      "depth : 31\n",
      "depth : 32\n",
      "depth : 33\n",
      "depth : 34\n",
      "depth : 35\n",
      "depth : 36\n",
      "depth : 37\n",
      "depth : 38\n",
      "depth : 39\n",
      "depth : 40\n",
      "n : 39\n",
      "depth : 20\n",
      "depth : 21\n",
      "depth : 22\n",
      "depth : 23\n",
      "depth : 24\n",
      "depth : 25\n",
      "depth : 26\n",
      "depth : 27\n",
      "depth : 28\n",
      "depth : 29\n",
      "depth : 30\n",
      "depth : 31\n",
      "depth : 32\n",
      "depth : 33\n",
      "depth : 34\n",
      "depth : 35\n",
      "depth : 36\n",
      "depth : 37\n",
      "depth : 38\n",
      "depth : 39\n",
      "depth : 40\n",
      "n : 40\n",
      "     n max       acc       auc\n",
      "0   23  27  0.782143  0.823392\n",
      "0   31  21  0.778571  0.823294\n",
      "0   28  23  0.771429  0.804605\n",
      "0   34  31  0.771429  0.796082\n",
      "0   20  30  0.771429  0.807373\n",
      "..  ..  ..       ...       ...\n",
      "0   22  34  0.714286  0.785325\n",
      "0   24  24  0.714286  0.813883\n",
      "0   29  29  0.714286  0.796777\n",
      "0   30  20  0.714286  0.818855\n",
      "0   21  39  0.703571  0.793016\n",
      "\n",
      "[441 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df_rf_auc = pd.DataFrame(columns=['n', 'max', 'acc', 'auc'])\n",
    "for n in range(20, 41):\n",
    "    for max in range(20, 41):\n",
    "        rf_model = RandomForestClassifier(n_estimators=n, max_depth=max)\n",
    "        rf_model.fit(ml_train.iloc[:, 1:], ml_train.iloc[:, 0])\n",
    "        rf_model_prob = rf_model.predict_proba(ml_test.iloc[:, 1:])\n",
    "        acc = np.mean(rf_model.predict(ml_test.iloc[:, 1:]) == ml_test.iloc[:, 0])\n",
    "        auc = roc_auc_score(y_true, rf_model_prob, multi_class='ovr')\n",
    "        # df_rf_auc = df_rf_auc.append({'n': n, 'max': max, 'acc': acc, 'auc': auc}, ignore_index=True)\n",
    "        df_rf_auc = pd.concat([df_rf_auc, pd.DataFrame.from_records([{'n': n, 'max': max, 'acc': acc, 'auc': auc}])])\n",
    "        # print('depth :',max)\n",
    "    print('n :',n)\n",
    "df_rf_auc = df_rf_auc.sort_values(by='acc', ascending=False)\n",
    "print(df_rf_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898f3991",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1cfa238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "0.7535714285714286\n",
      "0.5087954504004019\n"
     ]
    }
   ],
   "source": [
    "ml_train_num = ml_train.copy()\n",
    "ml_train_num['tag'] = ml_train_num['tag'].replace({'pop': 0, 'hiphop': 1, 'rock': 2, 'folk': 3})\n",
    "ml_test_num = ml_test.copy()\n",
    "ml_test_num['tag'] = ml_test_num['tag'].replace({'pop': 0, 'hiphop': 1, 'rock': 2, 'folk': 3})\n",
    "train_matrix = xgb.DMatrix(data=ml_train_num.iloc[:, 1:], label=ml_train_num.iloc[:, 0])\n",
    "test_matrix = xgb.DMatrix(data=ml_test_num.iloc[:, 1:], label=ml_test_num.iloc[:, 0])\n",
    "best_param = {'objective': 'multi:softprob', 'eval_metric': 'mlogloss', 'num_class': 4}\n",
    "best_seednumber = 1234\n",
    "best_logloss = float('inf')\n",
    "best_logloss_index = 0\n",
    "for iter in range(1, 11):\n",
    "    param = best_param.copy()\n",
    "    param['max_depth'] = np.random.randint(2, 6)\n",
    "    param['eta'] = np.random.uniform(0.01, 0.3)\n",
    "    seed_number=np.random.randint(10000)\n",
    "    cv_result = xgb.cv(params=param, dtrain=train_matrix, num_boost_round=1000, nfold=5, early_stopping_rounds=8, seed=seed_number)\n",
    "    min_logloss = cv_result['test-mlogloss-mean'].min()\n",
    "    min_logloss_index = cv_result['test-mlogloss-mean'].idxmin()\n",
    "    if min_logloss < best_logloss:\n",
    "        best_logloss = min_logloss\n",
    "        best_logloss_index = min_logloss_index\n",
    "        best_seednumber = seed_number\n",
    "    print(iter)\n",
    "nround = best_logloss_index\n",
    "bst_model = xgb.train(params=best_param, dtrain=train_matrix, num_boost_round=nround)\n",
    "test_pred = bst_model.predict(test_matrix)\n",
    "test_prediction = pd.DataFrame(test_pred).apply(lambda x: np.argmax(x), axis=1)\n",
    "print(np.mean(test_prediction.to_numpy() == ml_test_num.iloc[:, 0].to_numpy()))\n",
    "print(roc_auc_score(y_true, test_pred, multi_class='ovr'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44faa7bb",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c2bc0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4381/1694111673.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_predict.loc[:,'release_year'] = pd.to_datetime(data_predict.loc[:,'release_date']).dt.year\n",
      "/tmp/ipykernel_4381/1694111673.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_predict.loc[:,'tag_bin'] = np.where(data_predict.loc[:,'tag'] == 'hiphop', 'hiphop', 'nonhiphop')\n",
      "/tmp/ipykernel_4381/1694111673.py:4: FutureWarning: Comparison of Timestamp with datetime.date is deprecated in order to match the standard library behavior. In a future version these will be considered non-comparable. Use 'ts == pd.Timestamp(date)' or 'ts.date() == date' instead.\n",
      "  data_predict.loc[:,'treatment_date'] = np.where(data_predict.loc[:,'release_date'] < pd.to_datetime('2017-06-24'), 0, 1)\n",
      "/tmp/ipykernel_4381/1694111673.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_predict.loc[:,'treatment_date'] = np.where(data_predict.loc[:,'release_date'] < pd.to_datetime('2017-06-24'), 0, 1)\n",
      "/tmp/ipykernel_4381/1694111673.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_predict.loc[:,'treatment_year'] = np.where(data_predict.loc[:,'release_year'] < 2017, 0, 1)\n"
     ]
    }
   ],
   "source": [
    "data_predict = data[data['release_year'].isin([2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019])]\n",
    "data_predict.loc[:,'release_year'] = pd.to_datetime(data_predict.loc[:,'release_date']).dt.year\n",
    "data_predict.loc[:,'tag_bin'] = np.where(data_predict.loc[:,'tag'] == 'hiphop', 'hiphop', 'nonhiphop')\n",
    "data_predict.loc[:,'treatment_date'] = np.where(data_predict.loc[:,'release_date'] < pd.to_datetime('2017-06-24'), 0, 1)\n",
    "data_predict.loc[:,'treatment_year'] = np.where(data_predict.loc[:,'release_year'] < 2017, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2287750",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25e44384",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4381/443113763.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_predict.loc[:,'gnb_pred'] = nb_model.predict(data_predict.iloc[:, 6:17])\n",
      "/tmp/ipykernel_4381/443113763.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_predict.loc[:,'gnb_pred_acc'] = data_predict['gnb_pred'] == data_predict['tag']\n",
      "/tmp/ipykernel_4381/443113763.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_predict.loc[:,'gnb_pred_bin'] = np.where(data_predict['gnb_pred'] == 'hiphop', 'hiphop', 'nonhiphop')\n",
      "/tmp/ipykernel_4381/443113763.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_predict.loc[:,'gnb_pred_bin_acc'] = data_predict['tag_bin'] == data_predict['gnb_pred_bin']\n"
     ]
    }
   ],
   "source": [
    "data_predict.loc[:,'gnb_pred'] = nb_model.predict(data_predict.iloc[:, 6:17])\n",
    "data_predict.loc[:,'gnb_pred_acc'] = data_predict['gnb_pred'] == data_predict['tag']\n",
    "data_predict.loc[:,'gnb_pred_bin'] = np.where(data_predict['gnb_pred'] == 'hiphop', 'hiphop', 'nonhiphop')\n",
    "data_predict.loc[:,'gnb_pred_bin_acc'] = data_predict['tag_bin'] == data_predict['gnb_pred_bin']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e786d06",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bb586e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4381/134867769.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_predict['knn_pred'] = knn_model.predict(data_predict.iloc[:, 6:17])\n",
      "/tmp/ipykernel_4381/134867769.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_predict['knn_pred_acc'] = data_predict['knn_pred'] == data_predict['tag']\n",
      "/tmp/ipykernel_4381/134867769.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_predict['knn_pred_bin'] = np.where(data_predict['knn_pred'] == 'hiphop', 'hiphop', 'nonhiphop')\n",
      "/tmp/ipykernel_4381/134867769.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_predict['knn_pred_bin_acc'] = data_predict['tag_bin'] == data_predict['knn_pred_bin']\n"
     ]
    }
   ],
   "source": [
    "data_predict['knn_pred'] = knn_model.predict(data_predict.iloc[:, 6:17])\n",
    "data_predict['knn_pred_acc'] = data_predict['knn_pred'] == data_predict['tag']\n",
    "data_predict['knn_pred_bin'] = np.where(data_predict['knn_pred'] == 'hiphop', 'hiphop', 'nonhiphop')\n",
    "data_predict['knn_pred_bin_acc'] = data_predict['tag_bin'] == data_predict['knn_pred_bin']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbee611b",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48e817ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4381/309029341.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_predict['rf_pred'] = rf_model.predict(data_predict.iloc[:, 6:17])\n",
      "/tmp/ipykernel_4381/309029341.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_predict['rf_pred_acc'] = data_predict['rf_pred'] == data_predict['tag']\n",
      "/tmp/ipykernel_4381/309029341.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_predict['rf_pred_bin'] = np.where(data_predict['rf_pred'] == 'hiphop', 'hiphop', 'nonhiphop')\n",
      "/tmp/ipykernel_4381/309029341.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_predict['rf_pred_bin_acc'] = data_predict['tag_bin'] == data_predict['rf_pred_bin']\n"
     ]
    }
   ],
   "source": [
    "data_predict['rf_pred'] = rf_model.predict(data_predict.iloc[:, 6:17])\n",
    "data_predict['rf_pred_acc'] = data_predict['rf_pred'] == data_predict['tag']\n",
    "data_predict['rf_pred_bin'] = np.where(data_predict['rf_pred'] == 'hiphop', 'hiphop', 'nonhiphop')\n",
    "data_predict['rf_pred_bin_acc'] = data_predict['tag_bin'] == data_predict['rf_pred_bin']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47108a80",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c5fd609",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4381/1823267812.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_predict['xgb_pred'] = pd.DataFrame(data_predict_xgb).apply(lambda x: np.argmax(x) + 1, axis=1)\n",
      "/tmp/ipykernel_4381/1823267812.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_predict['xgb_pred_acc'] = data_predict['xgb_pred'] == data_predict['tag']\n",
      "/tmp/ipykernel_4381/1823267812.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_predict['xgb_pred_bin'] = np.where(data_predict['xgb_pred'] == 'hiphop', 'hiphop', 'nonhiphop')\n",
      "/tmp/ipykernel_4381/1823267812.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_predict['xgb_pred_bin_acc'] = data_predict['tag_bin'] == data_predict['xgb_pred_bin']\n"
     ]
    }
   ],
   "source": [
    "data_predict_xgb = bst_model.predict(xgb.DMatrix(data_predict.iloc[:, 6:17]))\n",
    "data_predict['xgb_pred'] = pd.DataFrame(data_predict_xgb).apply(lambda x: np.argmax(x) + 1, axis=1)\n",
    "data_predict['xgb_pred_acc'] = data_predict['xgb_pred'] == data_predict['tag']\n",
    "data_predict['xgb_pred_bin'] = np.where(data_predict['xgb_pred'] == 'hiphop', 'hiphop', 'nonhiphop')\n",
    "data_predict['xgb_pred_bin_acc'] = data_predict['tag_bin'] == data_predict['xgb_pred_bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd1c7a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            song_id   tag release_date  release_month  release_year  \\\n",
      "1       xNgVaKafcd0   pop   2017-09-08    2017.666667          2017   \n",
      "2       mSOdaq656ff  rock   2015-11-11    2015.833333          2015   \n",
      "3      bqv5oMs3aac9   pop   2016-05-24    2016.333333          2016   \n",
      "4       xLBr1fbf8ac   pop   2015-06-27    2015.416667          2015   \n",
      "5      bqwPhDt3af1d   pop   2016-04-14    2016.250000          2016   \n",
      "...             ...   ...          ...            ...           ...   \n",
      "94811   mSFWvm87f0a   pop   2012-07-12    2012.500000          2012   \n",
      "94812   xNPVxjbf14e   pop   2015-04-08    2015.250000          2015   \n",
      "94813   8IAUlNe26fb   pop   2015-04-08    2015.250000          2015   \n",
      "94814  bCniNa4469b4   pop   2016-04-08    2016.250000          2016   \n",
      "94815   xNPVxla3162   pop   2015-04-08    2015.250000          2015   \n",
      "\n",
      "       listen_times  chroma_stft_norm  rmse_norm  spectral_centroid_norm  \\\n",
      "1             952.0          0.313235   0.226911                0.325286   \n",
      "2             601.0          0.553648   0.305978                0.255246   \n",
      "3             425.0          0.317953   0.153784                0.248175   \n",
      "4           42450.0          0.295309   0.174921                0.247695   \n",
      "5             352.0          0.359844   0.161044                0.276050   \n",
      "...             ...               ...        ...                     ...   \n",
      "94811          24.0          0.420810   0.162462                0.345590   \n",
      "94812         172.0          0.302126   0.199702                0.278044   \n",
      "94813          84.0          0.584518   0.210099                0.487939   \n",
      "94814         222.0          0.367468   0.317775                0.482698   \n",
      "94815         252.0          0.536630   0.488423                0.367835   \n",
      "\n",
      "       spectral_bandwidth_norm  ...  knn_pred_bin  knn_pred_bin_acc  rf_pred  \\\n",
      "1                     0.570343  ...     nonhiphop              True     folk   \n",
      "2                     0.479821  ...     nonhiphop              True     rock   \n",
      "3                     0.558457  ...     nonhiphop              True      pop   \n",
      "4                     0.550785  ...     nonhiphop              True      pop   \n",
      "5                     0.628411  ...     nonhiphop              True      pop   \n",
      "...                        ...  ...           ...               ...      ...   \n",
      "94811                 0.702055  ...     nonhiphop              True      pop   \n",
      "94812                 0.568268  ...     nonhiphop              True      pop   \n",
      "94813                 0.758034  ...     nonhiphop              True   hiphop   \n",
      "94814                 0.781361  ...     nonhiphop              True      pop   \n",
      "94815                 0.685609  ...     nonhiphop              True     rock   \n",
      "\n",
      "       rf_pred_acc  rf_pred_bin  rf_pred_bin_acc  xgb_pred  xgb_pred_acc  \\\n",
      "1            False    nonhiphop             True       3.0         False   \n",
      "2             True    nonhiphop             True       1.0         False   \n",
      "3             True    nonhiphop             True       1.0         False   \n",
      "4             True    nonhiphop             True       1.0         False   \n",
      "5             True    nonhiphop             True       1.0         False   \n",
      "...            ...          ...              ...       ...           ...   \n",
      "94811         True    nonhiphop             True       NaN         False   \n",
      "94812         True    nonhiphop             True       NaN         False   \n",
      "94813        False       hiphop            False       NaN         False   \n",
      "94814         True    nonhiphop             True       NaN         False   \n",
      "94815        False    nonhiphop             True       NaN         False   \n",
      "\n",
      "       xgb_pred_bin  xgb_pred_bin_acc  \n",
      "1         nonhiphop              True  \n",
      "2         nonhiphop              True  \n",
      "3         nonhiphop              True  \n",
      "4         nonhiphop              True  \n",
      "5         nonhiphop              True  \n",
      "...             ...               ...  \n",
      "94811     nonhiphop              True  \n",
      "94812     nonhiphop              True  \n",
      "94813     nonhiphop              True  \n",
      "94814     nonhiphop              True  \n",
      "94815     nonhiphop              True  \n",
      "\n",
      "[69427 rows x 51 columns]\n",
      "Index(['song_id', 'tag', 'release_date', 'release_month', 'release_year',\n",
      "       'listen_times', 'chroma_stft_norm', 'rmse_norm',\n",
      "       'spectral_centroid_norm', 'spectral_bandwidth_norm', 'rolloff_norm',\n",
      "       'zero_crossing_rate_norm', 'mfcc1_norm', 'mfcc2_norm', 'mfcc3_norm',\n",
      "       'mfcc4_norm', 'mfcc5_norm', 'mfcc6_norm', 'mfcc7_norm', 'mfcc8_norm',\n",
      "       'mfcc9_norm', 'mfcc10_norm', 'mfcc11_norm', 'mfcc12_norm',\n",
      "       'mfcc13_norm', 'mfcc14_norm', 'mfcc15_norm', 'mfcc16_norm',\n",
      "       'mfcc17_norm', 'mfcc18_norm', 'mfcc19_norm', 'mfcc20_norm', 'tag_bin',\n",
      "       'treatment_date', 'treatment_year', 'gnb_pred', 'gnb_pred_acc',\n",
      "       'gnb_pred_bin', 'gnb_pred_bin_acc', 'knn_pred', 'knn_pred_acc',\n",
      "       'knn_pred_bin', 'knn_pred_bin_acc', 'rf_pred', 'rf_pred_acc',\n",
      "       'rf_pred_bin', 'rf_pred_bin_acc', 'xgb_pred', 'xgb_pred_acc',\n",
      "       'xgb_pred_bin', 'xgb_pred_bin_acc'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data_predict)\n",
    "print(data_predict.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e32430c",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea75324",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5986e943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    release_year  treatment_year  gnb_pred_acc  gnb_pred_bin_acc  gnb_recall  \\\n",
      "0           2009               0      0.612303          0.949928    0.351852   \n",
      "1           2010               0      0.540745          0.890082    0.087591   \n",
      "2           2011               0      0.468852          0.902732    0.088496   \n",
      "3           2012               0      0.492995          0.863398    0.118081   \n",
      "4           2013               0      0.484879          0.878696    0.105096   \n",
      "5           2014               0      0.435321          0.830444    0.108209   \n",
      "6           2015               0      0.427329          0.854805    0.144880   \n",
      "7           2016               0      0.448048          0.866135    0.117786   \n",
      "8           2017               1      0.457009          0.818925    0.124736   \n",
      "9           2018               1      0.477833          0.791087    0.110286   \n",
      "10          2019               1      0.439056          0.764987    0.111064   \n",
      "\n",
      "    gnb_precision  \n",
      "0        0.351852  \n",
      "1        0.196721  \n",
      "2        0.117647  \n",
      "3        0.304762  \n",
      "4        0.292035  \n",
      "5        0.334615  \n",
      "6        0.399399  \n",
      "7        0.307692  \n",
      "8        0.536364  \n",
      "9        0.533245  \n",
      "10       0.499048  \n",
      "Index(['release_year', 'treatment_year', 'gnb_pred_acc', 'gnb_pred_bin_acc',\n",
      "       'gnb_recall', 'gnb_precision'],\n",
      "      dtype='object')\n",
      "    release_year  treatment_year           metrics    values\n",
      "0           2009               0      gnb_pred_acc  0.612303\n",
      "1           2010               0      gnb_pred_acc  0.540745\n",
      "2           2011               0      gnb_pred_acc  0.468852\n",
      "3           2012               0      gnb_pred_acc  0.492995\n",
      "4           2013               0      gnb_pred_acc  0.484879\n",
      "5           2014               0      gnb_pred_acc  0.435321\n",
      "6           2015               0      gnb_pred_acc  0.427329\n",
      "7           2016               0      gnb_pred_acc  0.448048\n",
      "8           2017               1      gnb_pred_acc  0.457009\n",
      "9           2018               1      gnb_pred_acc  0.477833\n",
      "10          2019               1      gnb_pred_acc  0.439056\n",
      "11          2009               0  gnb_pred_bin_acc  0.949928\n",
      "12          2010               0  gnb_pred_bin_acc  0.890082\n",
      "13          2011               0  gnb_pred_bin_acc  0.902732\n",
      "14          2012               0  gnb_pred_bin_acc  0.863398\n",
      "15          2013               0  gnb_pred_bin_acc  0.878696\n",
      "16          2014               0  gnb_pred_bin_acc  0.830444\n",
      "17          2015               0  gnb_pred_bin_acc  0.854805\n",
      "18          2016               0  gnb_pred_bin_acc  0.866135\n",
      "19          2017               1  gnb_pred_bin_acc  0.818925\n",
      "20          2018               1  gnb_pred_bin_acc  0.791087\n",
      "21          2019               1  gnb_pred_bin_acc  0.764987\n",
      "22          2009               0        gnb_recall  0.351852\n",
      "23          2010               0        gnb_recall  0.087591\n",
      "24          2011               0        gnb_recall  0.088496\n",
      "25          2012               0        gnb_recall  0.118081\n",
      "26          2013               0        gnb_recall  0.105096\n",
      "27          2014               0        gnb_recall  0.108209\n",
      "28          2015               0        gnb_recall  0.144880\n",
      "29          2016               0        gnb_recall  0.117786\n",
      "30          2017               1        gnb_recall  0.124736\n",
      "31          2018               1        gnb_recall  0.110286\n",
      "32          2019               1        gnb_recall  0.111064\n",
      "33          2009               0     gnb_precision  0.351852\n",
      "34          2010               0     gnb_precision  0.196721\n",
      "35          2011               0     gnb_precision  0.117647\n",
      "36          2012               0     gnb_precision  0.304762\n",
      "37          2013               0     gnb_precision  0.292035\n",
      "38          2014               0     gnb_precision  0.334615\n",
      "39          2015               0     gnb_precision  0.399399\n",
      "40          2016               0     gnb_precision  0.307692\n",
      "41          2017               1     gnb_precision  0.536364\n",
      "42          2018               1     gnb_precision  0.533245\n",
      "43          2019               1     gnb_precision  0.499048\n"
     ]
    }
   ],
   "source": [
    "gnb_mean_acc_tbyyear     = data_predict.copy().groupby(['release_year', 'treatment_year'])['gnb_pred_acc'].mean().reset_index()\n",
    "gnb_mean_bin_acc_tbyyear = data_predict.copy().groupby(['release_year', 'treatment_year'])['gnb_pred_bin_acc'].mean().reset_index()\n",
    "gnb_recall_tbyyear       = data_predict.copy()[data_predict['tag'] == 'hiphop'].groupby(['release_year', 'treatment_year'])['gnb_pred_acc'].mean().reset_index().rename(columns={'gnb_pred_acc':'gnb_recall'})\n",
    "gnb_precision_tbyyear    = data_predict.copy()[data_predict['gnb_pred'] == 'hiphop'].groupby(['release_year', 'treatment_year'])['gnb_pred_acc'].mean().reset_index().rename(columns={'gnb_pred_acc':'gnb_precision'})\n",
    "gnb_metrics = pd.concat([gnb_mean_acc_tbyyear, gnb_mean_bin_acc_tbyyear['gnb_pred_bin_acc'], gnb_recall_tbyyear['gnb_recall'], gnb_precision_tbyyear['gnb_precision']], axis=1)\n",
    "print(gnb_metrics)\n",
    "print(gnb_metrics.columns)\n",
    "gnb_metrics = gnb_metrics.melt(id_vars=['release_year', 'treatment_year'], var_name='metrics', value_name='values')\n",
    "print(gnb_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88df2845",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e5e90e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    release_year  treatment_year  knn_pred_acc  knn_pred_bin_acc  knn_recall  \\\n",
      "0           2009               0      0.734621          0.961373    0.000000   \n",
      "1           2010               0      0.686671          0.913455    0.000000   \n",
      "2           2011               0      0.571038          0.938251    0.000000   \n",
      "3           2012               0      0.561734          0.881349    0.000000   \n",
      "4           2013               0      0.570901          0.894489    0.000000   \n",
      "5           2014               0      0.477043          0.846828    0.000000   \n",
      "6           2015               0      0.443396          0.864682    0.000000   \n",
      "7           2016               0      0.534360          0.883315    0.000000   \n",
      "8           2017               1      0.509735          0.815810    0.000000   \n",
      "9           2018               1      0.563647          0.788232    0.000275   \n",
      "10          2019               1      0.545210          0.765087    0.000000   \n",
      "\n",
      "    knn_precision  \n",
      "0             1.0  \n",
      "1             NaN  \n",
      "2             NaN  \n",
      "3             NaN  \n",
      "4             NaN  \n",
      "5             NaN  \n",
      "6             NaN  \n",
      "7             NaN  \n",
      "8             NaN  \n",
      "9             NaN  \n",
      "10            NaN  \n",
      "    release_year  treatment_year           metrics    values\n",
      "0           2009               0      knn_pred_acc  0.734621\n",
      "1           2010               0      knn_pred_acc  0.686671\n",
      "2           2011               0      knn_pred_acc  0.571038\n",
      "3           2012               0      knn_pred_acc  0.561734\n",
      "4           2013               0      knn_pred_acc  0.570901\n",
      "5           2014               0      knn_pred_acc  0.477043\n",
      "6           2015               0      knn_pred_acc  0.443396\n",
      "7           2016               0      knn_pred_acc  0.534360\n",
      "8           2017               1      knn_pred_acc  0.509735\n",
      "9           2018               1      knn_pred_acc  0.563647\n",
      "10          2019               1      knn_pred_acc  0.545210\n",
      "11          2009               0  knn_pred_bin_acc  0.961373\n",
      "12          2010               0  knn_pred_bin_acc  0.913455\n",
      "13          2011               0  knn_pred_bin_acc  0.938251\n",
      "14          2012               0  knn_pred_bin_acc  0.881349\n",
      "15          2013               0  knn_pred_bin_acc  0.894489\n",
      "16          2014               0  knn_pred_bin_acc  0.846828\n",
      "17          2015               0  knn_pred_bin_acc  0.864682\n",
      "18          2016               0  knn_pred_bin_acc  0.883315\n",
      "19          2017               1  knn_pred_bin_acc  0.815810\n",
      "20          2018               1  knn_pred_bin_acc  0.788232\n",
      "21          2019               1  knn_pred_bin_acc  0.765087\n",
      "22          2009               0        knn_recall  0.000000\n",
      "23          2010               0        knn_recall  0.000000\n",
      "24          2011               0        knn_recall  0.000000\n",
      "25          2012               0        knn_recall  0.000000\n",
      "26          2013               0        knn_recall  0.000000\n",
      "27          2014               0        knn_recall  0.000000\n",
      "28          2015               0        knn_recall  0.000000\n",
      "29          2016               0        knn_recall  0.000000\n",
      "30          2017               1        knn_recall  0.000000\n",
      "31          2018               1        knn_recall  0.000275\n",
      "32          2019               1        knn_recall  0.000000\n",
      "33          2009               0     knn_precision  1.000000\n",
      "34          2010               0     knn_precision       NaN\n",
      "35          2011               0     knn_precision       NaN\n",
      "36          2012               0     knn_precision       NaN\n",
      "37          2013               0     knn_precision       NaN\n",
      "38          2014               0     knn_precision       NaN\n",
      "39          2015               0     knn_precision       NaN\n",
      "40          2016               0     knn_precision       NaN\n",
      "41          2017               1     knn_precision       NaN\n",
      "42          2018               1     knn_precision       NaN\n",
      "43          2019               1     knn_precision       NaN\n"
     ]
    }
   ],
   "source": [
    "knn_mean_acc_tbyyear     = data_predict.copy().groupby(['release_year', 'treatment_year'])['knn_pred_acc'].mean().reset_index()\n",
    "knn_mean_bin_acc_tbyyear = data_predict.copy().groupby(['release_year', 'treatment_year'])['knn_pred_bin_acc'].mean().reset_index()\n",
    "knn_recall_tbyyear       = data_predict.copy()[data_predict['tag'] == 'hiphop'].groupby(['release_year', 'treatment_year'])['knn_pred_acc'].mean().reset_index().rename(columns={'knn_pred_acc':'knn_recall'})\n",
    "knn_precision_tbyyear    = data_predict.copy()[data_predict['knn_pred'] == 'hiphop'].groupby(['release_year', 'treatment_year'])['knn_pred_acc'].mean().reset_index().rename(columns={'knn_pred_acc':'knn_precision'})\n",
    "knn_metrics = pd.concat([knn_mean_acc_tbyyear, knn_mean_bin_acc_tbyyear['knn_pred_bin_acc'], knn_recall_tbyyear['knn_recall'], knn_precision_tbyyear['knn_precision']], axis=1)\n",
    "print(knn_metrics)\n",
    "knn_metrics = knn_metrics.melt(id_vars=['release_year', 'treatment_year'], var_name='metrics', value_name='values')\n",
    "print(knn_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa16254",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa3f680d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    release_year  treatment_year  rf_pred_acc  rf_pred_bin_acc  rf_recall  \\\n",
      "0           2009               0     0.948498         0.991416   0.851852   \n",
      "1           2010               0     0.674037         0.910929   0.124088   \n",
      "2           2011               0     0.572678         0.930055   0.053097   \n",
      "3           2012               0     0.585814         0.884413   0.084871   \n",
      "4           2013               0     0.560148         0.895161   0.070064   \n",
      "5           2014               0     0.495904         0.850638   0.075871   \n",
      "6           2015               0     0.460495         0.867188   0.081699   \n",
      "7           2016               0     0.519516         0.881803   0.063604   \n",
      "8           2017               1     0.515966         0.825545   0.092178   \n",
      "9           2018               1     0.557297         0.800816   0.105886   \n",
      "10          2019               1     0.533260         0.774945   0.102162   \n",
      "\n",
      "    rf_precision  \n",
      "0       0.920000  \n",
      "1       0.447368  \n",
      "2       0.222222  \n",
      "3       0.589744  \n",
      "4       0.523810  \n",
      "5       0.598039  \n",
      "6       0.563910  \n",
      "7       0.453782  \n",
      "8       0.700965  \n",
      "9       0.696203  \n",
      "10      0.629243  \n",
      "    release_year  treatment_year          metrics    values\n",
      "0           2009               0      rf_pred_acc  0.948498\n",
      "1           2010               0      rf_pred_acc  0.674037\n",
      "2           2011               0      rf_pred_acc  0.572678\n",
      "3           2012               0      rf_pred_acc  0.585814\n",
      "4           2013               0      rf_pred_acc  0.560148\n",
      "5           2014               0      rf_pred_acc  0.495904\n",
      "6           2015               0      rf_pred_acc  0.460495\n",
      "7           2016               0      rf_pred_acc  0.519516\n",
      "8           2017               1      rf_pred_acc  0.515966\n",
      "9           2018               1      rf_pred_acc  0.557297\n",
      "10          2019               1      rf_pred_acc  0.533260\n",
      "11          2009               0  rf_pred_bin_acc  0.991416\n",
      "12          2010               0  rf_pred_bin_acc  0.910929\n",
      "13          2011               0  rf_pred_bin_acc  0.930055\n",
      "14          2012               0  rf_pred_bin_acc  0.884413\n",
      "15          2013               0  rf_pred_bin_acc  0.895161\n",
      "16          2014               0  rf_pred_bin_acc  0.850638\n",
      "17          2015               0  rf_pred_bin_acc  0.867188\n",
      "18          2016               0  rf_pred_bin_acc  0.881803\n",
      "19          2017               1  rf_pred_bin_acc  0.825545\n",
      "20          2018               1  rf_pred_bin_acc  0.800816\n",
      "21          2019               1  rf_pred_bin_acc  0.774945\n",
      "22          2009               0        rf_recall  0.851852\n",
      "23          2010               0        rf_recall  0.124088\n",
      "24          2011               0        rf_recall  0.053097\n",
      "25          2012               0        rf_recall  0.084871\n",
      "26          2013               0        rf_recall  0.070064\n",
      "27          2014               0        rf_recall  0.075871\n",
      "28          2015               0        rf_recall  0.081699\n",
      "29          2016               0        rf_recall  0.063604\n",
      "30          2017               1        rf_recall  0.092178\n",
      "31          2018               1        rf_recall  0.105886\n",
      "32          2019               1        rf_recall  0.102162\n",
      "33          2009               0     rf_precision  0.920000\n",
      "34          2010               0     rf_precision  0.447368\n",
      "35          2011               0     rf_precision  0.222222\n",
      "36          2012               0     rf_precision  0.589744\n",
      "37          2013               0     rf_precision  0.523810\n",
      "38          2014               0     rf_precision  0.598039\n",
      "39          2015               0     rf_precision  0.563910\n",
      "40          2016               0     rf_precision  0.453782\n",
      "41          2017               1     rf_precision  0.700965\n",
      "42          2018               1     rf_precision  0.696203\n",
      "43          2019               1     rf_precision  0.629243\n"
     ]
    }
   ],
   "source": [
    "rf_mean_acc_tbyyear     = data_predict.copy().groupby(['release_year', 'treatment_year'])['rf_pred_acc'].mean().reset_index()\n",
    "rf_mean_bin_acc_tbyyear = data_predict.copy().groupby(['release_year', 'treatment_year'])['rf_pred_bin_acc'].mean().reset_index()\n",
    "rf_recall_tbyyear       = data_predict.copy()[data_predict['tag'] == 'hiphop'].groupby(['release_year', 'treatment_year'])['rf_pred_acc'].mean().reset_index().rename(columns={'rf_pred_acc':'rf_recall'})\n",
    "rf_precision_tbyyear    = data_predict.copy()[data_predict['rf_pred'] == 'hiphop'].groupby(['release_year', 'treatment_year'])['rf_pred_acc'].mean().reset_index().rename(columns={'rf_pred_acc':'rf_precision'})\n",
    "rf_metrics = pd.concat([rf_mean_acc_tbyyear, rf_mean_bin_acc_tbyyear['rf_pred_bin_acc'], rf_recall_tbyyear['rf_recall'], rf_precision_tbyyear['rf_precision']], axis=1)\n",
    "print(rf_metrics)\n",
    "rf_metrics = rf_metrics.melt(id_vars=['release_year', 'treatment_year'], var_name='metrics', value_name='values')\n",
    "print(rf_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3e0e3a",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17412948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    release_year  treatment_year  xgb_pred_acc  xgb_pred_bin_acc  xgb_recall  \\\n",
      "0           2009               0           0.0          0.961373         0.0   \n",
      "1           2010               0           0.0          0.913455         0.0   \n",
      "2           2011               0           0.0          0.938251         0.0   \n",
      "3           2012               0           0.0          0.881349         0.0   \n",
      "4           2013               0           0.0          0.894489         0.0   \n",
      "5           2014               0           0.0          0.846828         0.0   \n",
      "6           2015               0           0.0          0.864682         0.0   \n",
      "7           2016               0           0.0          0.883315         0.0   \n",
      "8           2017               1           0.0          0.815810         0.0   \n",
      "9           2018               1           0.0          0.788174         0.0   \n",
      "10          2019               1           0.0          0.765087         0.0   \n",
      "\n",
      "    xgb_precision  \n",
      "0             NaN  \n",
      "1             NaN  \n",
      "2             NaN  \n",
      "3             NaN  \n",
      "4             NaN  \n",
      "5             NaN  \n",
      "6             NaN  \n",
      "7             NaN  \n",
      "8             NaN  \n",
      "9             NaN  \n",
      "10            NaN  \n",
      "    release_year  treatment_year           metrics    values\n",
      "0           2009               0      xgb_pred_acc  0.000000\n",
      "1           2010               0      xgb_pred_acc  0.000000\n",
      "2           2011               0      xgb_pred_acc  0.000000\n",
      "3           2012               0      xgb_pred_acc  0.000000\n",
      "4           2013               0      xgb_pred_acc  0.000000\n",
      "5           2014               0      xgb_pred_acc  0.000000\n",
      "6           2015               0      xgb_pred_acc  0.000000\n",
      "7           2016               0      xgb_pred_acc  0.000000\n",
      "8           2017               1      xgb_pred_acc  0.000000\n",
      "9           2018               1      xgb_pred_acc  0.000000\n",
      "10          2019               1      xgb_pred_acc  0.000000\n",
      "11          2009               0  xgb_pred_bin_acc  0.961373\n",
      "12          2010               0  xgb_pred_bin_acc  0.913455\n",
      "13          2011               0  xgb_pred_bin_acc  0.938251\n",
      "14          2012               0  xgb_pred_bin_acc  0.881349\n",
      "15          2013               0  xgb_pred_bin_acc  0.894489\n",
      "16          2014               0  xgb_pred_bin_acc  0.846828\n",
      "17          2015               0  xgb_pred_bin_acc  0.864682\n",
      "18          2016               0  xgb_pred_bin_acc  0.883315\n",
      "19          2017               1  xgb_pred_bin_acc  0.815810\n",
      "20          2018               1  xgb_pred_bin_acc  0.788174\n",
      "21          2019               1  xgb_pred_bin_acc  0.765087\n",
      "22          2009               0        xgb_recall  0.000000\n",
      "23          2010               0        xgb_recall  0.000000\n",
      "24          2011               0        xgb_recall  0.000000\n",
      "25          2012               0        xgb_recall  0.000000\n",
      "26          2013               0        xgb_recall  0.000000\n",
      "27          2014               0        xgb_recall  0.000000\n",
      "28          2015               0        xgb_recall  0.000000\n",
      "29          2016               0        xgb_recall  0.000000\n",
      "30          2017               1        xgb_recall  0.000000\n",
      "31          2018               1        xgb_recall  0.000000\n",
      "32          2019               1        xgb_recall  0.000000\n",
      "33          2009               0     xgb_precision       NaN\n",
      "34          2010               0     xgb_precision       NaN\n",
      "35          2011               0     xgb_precision       NaN\n",
      "36          2012               0     xgb_precision       NaN\n",
      "37          2013               0     xgb_precision       NaN\n",
      "38          2014               0     xgb_precision       NaN\n",
      "39          2015               0     xgb_precision       NaN\n",
      "40          2016               0     xgb_precision       NaN\n",
      "41          2017               1     xgb_precision       NaN\n",
      "42          2018               1     xgb_precision       NaN\n",
      "43          2019               1     xgb_precision       NaN\n"
     ]
    }
   ],
   "source": [
    "xgb_mean_acc_tbyyear     = data_predict.copy().groupby(['release_year', 'treatment_year'])['xgb_pred_acc'].mean().reset_index()\n",
    "xgb_mean_bin_acc_tbyyear = data_predict.copy().groupby(['release_year', 'treatment_year'])['xgb_pred_bin_acc'].mean().reset_index()\n",
    "xgb_recall_tbyyear       = data_predict.copy()[data_predict['tag'] == 'hiphop'].groupby(['release_year', 'treatment_year'])['xgb_pred_acc'].mean().reset_index().rename(columns={'xgb_pred_acc':'xgb_recall'})\n",
    "xgb_precision_tbyyear    = data_predict.copy()[data_predict['xgb_pred'] == 'hiphop'].groupby(['release_year', 'treatment_year'])['xgb_pred_acc'].mean().reset_index().rename(columns={'xgb_pred_acc':'xgb_precision'})\n",
    "xgb_metrics = pd.concat([xgb_mean_acc_tbyyear, xgb_mean_bin_acc_tbyyear['xgb_pred_bin_acc'], xgb_recall_tbyyear['xgb_recall'], xgb_precision_tbyyear['xgb_precision']], axis=1)\n",
    "print(xgb_metrics)\n",
    "xgb_metrics = xgb_metrics.melt(id_vars=['release_year', 'treatment_year'], var_name='metrics', value_name='values')\n",
    "print(xgb_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8b5537",
   "metadata": {},
   "source": [
    "## Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16f9d22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    release_year  treatment_year                   metrics         0\n",
      "0           2009               0      classifiers_pred_acc  0.573856\n",
      "1           2010               0      classifiers_pred_acc  0.475363\n",
      "2           2011               0      classifiers_pred_acc  0.403142\n",
      "3           2012               0      classifiers_pred_acc  0.410136\n",
      "4           2013               0      classifiers_pred_acc  0.403982\n",
      "5           2014               0      classifiers_pred_acc  0.352067\n",
      "6           2015               0      classifiers_pred_acc  0.332805\n",
      "7           2016               0      classifiers_pred_acc  0.375481\n",
      "8           2017               1      classifiers_pred_acc  0.370678\n",
      "9           2018               1      classifiers_pred_acc  0.399694\n",
      "10          2019               1      classifiers_pred_acc  0.379382\n",
      "11          2009               0  classifiers_pred_bin_acc  0.966023\n",
      "12          2010               0  classifiers_pred_bin_acc  0.906980\n",
      "13          2011               0  classifiers_pred_bin_acc  0.927322\n",
      "14          2012               0  classifiers_pred_bin_acc  0.877627\n",
      "15          2013               0  classifiers_pred_bin_acc  0.890709\n",
      "16          2014               0  classifiers_pred_bin_acc  0.843685\n",
      "17          2015               0  classifiers_pred_bin_acc  0.862839\n",
      "18          2016               0  classifiers_pred_bin_acc  0.878642\n",
      "19          2017               1  classifiers_pred_bin_acc  0.819023\n",
      "20          2018               1  classifiers_pred_bin_acc  0.792077\n",
      "21          2019               1  classifiers_pred_bin_acc  0.767526\n",
      "22          2009               0        classifiers_recall  0.300926\n",
      "23          2010               0        classifiers_recall  0.052920\n",
      "24          2011               0        classifiers_recall  0.035398\n",
      "25          2012               0        classifiers_recall  0.050738\n",
      "26          2013               0        classifiers_recall  0.043790\n",
      "27          2014               0        classifiers_recall  0.046020\n",
      "28          2015               0        classifiers_recall  0.056645\n",
      "29          2016               0        classifiers_recall  0.045347\n",
      "30          2017               1        classifiers_recall  0.054228\n",
      "31          2018               1        classifiers_recall  0.054112\n",
      "32          2019               1        classifiers_recall  0.053306\n",
      "33          2009               0     classifiers_precision  0.757284\n",
      "34          2010               0     classifiers_precision  0.322045\n",
      "35          2011               0     classifiers_precision  0.169935\n",
      "36          2012               0     classifiers_precision  0.447253\n",
      "37          2013               0     classifiers_precision  0.407922\n",
      "38          2014               0     classifiers_precision  0.466327\n",
      "39          2015               0     classifiers_precision  0.481655\n",
      "40          2016               0     classifiers_precision  0.380737\n",
      "41          2017               1     classifiers_precision  0.618664\n",
      "42          2018               1     classifiers_precision  0.614724\n",
      "43          2019               1     classifiers_precision  0.564145\n"
     ]
    }
   ],
   "source": [
    "average = pd.concat([gnb_metrics['values'], knn_metrics['values'], rf_metrics['values'], xgb_metrics['values']], names = ['values', 'values_1', 'values_2', 'values_3'], axis=1)\n",
    "average = average.mean(axis=1)\n",
    "average = pd.concat([gnb_metrics['release_year'], gnb_metrics['treatment_year'], gnb_metrics['metrics'], average],axis=1)\n",
    "average['metrics'] = average['metrics'].str.replace('gnb_', 'classifiers_')\n",
    "print(average)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
